{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1158ef128>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGj1JREFUeJzt3Xu0XWV97vHvI3gBucglTTEEgxLbAq1W0kjr6amWClSr\n0A6w8dhCeyi0hdrayzgKwwrVkw7psdLSHjliyeDiBRBvtEpphFaPrVyCpUJQDqlAIUSIBAkot8Dv\n/LHeXVe2OzuLy7tXsvP9jLHGmvM35zvXOzeMPHu+891zpaqQJKmnZ427A5Kk2c+wkSR1Z9hIkroz\nbCRJ3Rk2kqTuDBtJUneGjbQJSf4pyW88hXaVZL8efZris05L8uFptq9M8uqZ6Is0ne3H3QFpOklu\nA+YCjw+VX1pVd42nR1uXqjpgc/skWQDcCjy7qjb07pO2TV7ZaGvwhqraaej1fUGTxF+ctlD+txEY\nNtpKJVnQhquOS/IfwJWt/vEk30xyf5IvJjlgqM1Gw2JJfi3Jl4bWX5vk663tXwOZ5vO3S3JKkn9P\n8kCS65LMn2K/1yf51yTrk9yR5LShbc9L8uEk9yb5dpJrk8wd6ts32rFvTfKWaX4cz0lyftt3ZZJF\nQ59xW5Kfa8uLk6xofbk7yfvbbl9s799O8mCSn0zyrCTvTHJ7knva8XcdOu4xbdu9Sf540uecluSS\ndm7rgV9rn/3ldp5rkvx1kucMHa+SnJjklnYe70nykiT/0vp78fD+2voYNtra/QzwI8Bhbf0yYCHw\nA8BXgI+McpAkewKfBN4J7An8O/CqaZr8AfBm4HXALsB/B747xX7fAY4BXgC8HvjtJEe2bccCuwLz\ngT2A3wIeSvJ84Ezg56tqZ+CngOun6csbgQvbZ1wK/PUm9vtL4C+rahfgJcDFrf5f2/sL2pXjl4Ff\na6/XAC8Gdpo4bpL9gQ8AbwH2aucwb9JnHQFc0vr0EQbDoL/P4Gf7k8AhwImT2hwGHAQcDPwP4Gzg\nV9rP50AGP29tpQwbbQ0+3X4j/naST0/adlpVfaeqHgKoqmVV9UBVPQKcBrxs+DfyabwOWFlVl1TV\nY8BfAN+cZv/fAN5ZVTfXwL9V1b2Td6qqf6qqG6rqiar6KvAxBgEJ8BiDkNmvqh6vquuqan3b9gRw\nYJIdqmpNVa2cpi9fqqrPVdXjwAXAyzax32PAfkn2rKoHq+qqaY75FuD9VfWNqnoQOBlY0obEjgL+\ntqq+VFWPAu8CJj9k8ctV9el23g+1c7uqqjZU1W3AB4d+DhP+rKrWt3O9EfiH9vn3M/gl4sen6a+2\ncIaNtgZHVtUL2uvISdvumFhoQ1vvbUNb64Hb2qY9R/iMFw4fqwZPqL1j07szn8HVz7SSvDLJPyZZ\nm+R+BlcvE/25ALgcuDDJXUn+LMmzq+o7wC+3fdck+WySH57mY4ZD8bvA8zZxn+Q44KXA19uQ3S9M\nc8wXArcPrd/OYELRXL7/Z/VdYHLQbvSzS/LSJH/XhjjXA3/K9/93uXto+aEp1neapr/awhk22toN\n/0b93xgM3/wcg6GdBa0+ce/lO8COQ/v/4NDyGgYBMmiQZHh9CncwGIranI8yGNqaX1W7Av9noj9V\n9VhV/UlV7c9gqOwXGAy5UVWXV9VrGQxTfR340AifNa2quqWq3sxgiPF04JI2ZDfVo9/vAl40tL4P\nsIFBAKwB9p7YkGQHBldoG33cpPWzGJzHwjaMdwrT3BPT7GPYaDbZGXiEwW/ZOzL47XnY9cAvJdkx\ng7+DOW5o22eBA5L8Ursq+F02DqPJ/gZ4T5KFGfixJJP/wZ3o07qqejjJYgaBCECS1yT50STbAesZ\nDHM9kWRukiNaEDwCPMhgWO1pSfIrSeZU1RPAt1v5CWBte3/x0O4fA34/yb5JdmLws7yoTY2+BHhD\nkp9qN+1PY/PBsXM7xwfbVdpvP93z0dbFsNFscj6D4Z7VwE3A5HsSZwCPMvjt/DyGJg9U1beAo4H3\nMgirhcA/T/NZ72dwg/0fGPwjeg6wwxT7nQi8O8kDDO5tXDy07QcZ/MO9Hvga8AUGQ2vPYjAB4S5g\nHYN7G8/EP86HAyuTPMhgssCSdj/lu8BS4J/bfbGDgWWtL19k8Dc4DwNvBWj3VN7KYFLCGgZheA+D\nYNyUP2IQtA8wuEq76Bk4H21F4penSXo62pXPtxkMkd067v5oy+SVjaQnLckb2nDk84H3ATfwvQkZ\n0vcxbCQ9FUcwGOa7i8GQ45JymETTcBhNktSdVzaSpO4MG0lSdz6Ntdlzzz1rwYIF4+6GJG1Vrrvu\num9V1ZzN7WfYNAsWLGDFihXj7oYkbVWS3L75vRxGkyTNAMNGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ\n3Rk2kqTuDBtJUnf+UedWZsE7PjvuLswqt7339ePugrRN8MpGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ\n3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NG\nktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3XULmyTzk/xjkpuSrEzye61+WpLVSa5vr9cNtTk5yaokNyc5\nbKh+UJIb2rYzk6TVn5vkola/OsmCoTbHJrmlvY7tdZ6SpM3bvuOxNwB/WFVfSbIzcF2S5W3bGVX1\nvuGdk+wPLAEOAF4IfD7JS6vqceAs4HjgauBzwOHAZcBxwH1VtV+SJcDpwC8n2R04FVgEVPvsS6vq\nvo7nK0nahG5XNlW1pqq+0pYfAL4GzJumyRHAhVX1SFXdCqwCFifZC9ilqq6qqgLOB44canNeW74E\nOKRd9RwGLK+qdS1gljMIKEnSGMzIPZs2vPXjDK5MAN6a5KtJliXZrdXmAXcMNbuz1ea15cn1jdpU\n1QbgfmCPaY41uV8nJFmRZMXatWuf8vlJkqbXPWyS7AR8AnhbVa1nMCT2YuDlwBrgz3v3YVOq6uyq\nWlRVi+bMmTOubkjSrNc1bJI8m0HQfKSqPglQVXdX1eNV9QTwIWBx2301MH+o+d6ttrotT65v1CbJ\n9sCuwL3THEuSNAY9Z6MFOAf4WlW9f6i+19Buvwjc2JYvBZa0GWb7AguBa6pqDbA+ycHtmMcAnxlq\nMzHT7CjgynZf53Lg0CS7tWG6Q1tNkjQGPWejvQr4VeCGJNe32inAm5O8nMEssduA3wSoqpVJLgZu\nYjCT7aQ2Ew3gROBcYAcGs9Aua/VzgAuSrALWMZjNRlWtS/Ie4Nq237ural2n85QkbUa3sKmqLwGZ\nYtPnpmmzFFg6RX0FcOAU9YeBozdxrGXAslH7K0nqxycISJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvD\nRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdWfYSJK6\nM2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7rqFTZL5Sf4x\nyU1JVib5vVbfPcnyJLe0992G2pycZFWSm5McNlQ/KMkNbduZSdLqz01yUatfnWTBUJtj22fckuTY\nXucpSdq8nlc2G4A/rKr9gYOBk5LsD7wDuKKqFgJXtHXatiXAAcDhwAeSbNeOdRZwPLCwvQ5v9eOA\n+6pqP+AM4PR2rN2BU4FXAouBU4dDTZI0s7qFTVWtqaqvtOUHgK8B84AjgPPabucBR7blI4ALq+qR\nqroVWAUsTrIXsEtVXVVVBZw/qc3EsS4BDmlXPYcBy6tqXVXdByznewElSZphM3LPpg1v/ThwNTC3\nqta0Td8E5rblecAdQ83ubLV5bXlyfaM2VbUBuB/YY5pjSZLGoHvYJNkJ+ATwtqpaP7ytXalU7z5s\nSpITkqxIsmLt2rXj6oYkzXpdwybJsxkEzUeq6pOtfHcbGqO939Pqq4H5Q833brXVbXlyfaM2SbYH\ndgXuneZYG6mqs6tqUVUtmjNnzlM9TUnSZvScjRbgHOBrVfX+oU2XAhOzw44FPjNUX9JmmO3LYCLA\nNW3IbX2Sg9sxj5nUZuJYRwFXtquly4FDk+zWJgYc2mqSpDHYvuOxXwX8KnBDkutb7RTgvcDFSY4D\nbgfeBFBVK5NcDNzEYCbbSVX1eGt3InAusANwWXvBIMwuSLIKWMdgNhtVtS7Je4Br237vrqp1vU5U\nkjS9bmFTVV8CsonNh2yizVJg6RT1FcCBU9QfBo7exLGWActG7a8kqR+fICBJ6s6wkSR1Z9hIkroz\nbCRJ3Rk2kqTuDBtJUneGjSSpu5HCJsmP9u6IJGn2GvXK5gNJrklyYpJdu/ZIkjTrjBQ2VfXTwFsY\nPNzyuiQfTfLarj2TJM0aI9+zqapbgHcCbwd+BjgzydeT/FKvzkmSZodR79n8WJIzGHzb5s8Cb6iq\nH2nLZ3TsnyRpFhj1QZx/BfwNcEpVPTRRrKq7kryzS88kSbPGqGHzeuChiUf+J3kW8Lyq+m5VXdCt\nd5KkWWHUezafZ/BdMhN2bDVJkjZr1LB5XlU9OLHSlnfs0yVJ0mwzath8J8krJlaSHAQ8NM3+kiT9\np1Hv2bwN+HiSuxh8++YPAr/crVeSpFllpLCpqmuT/DDwQ610c1U91q9bkqTZZNQrG4CfABa0Nq9I\nQlWd36VXkqRZZaSwSXIB8BLgeuDxVi7AsJEkbdaoVzaLgP2rqnp2RpI0O406G+1GBpMCJEl60ka9\nstkTuCnJNcAjE8WqemOXXkmSZpVRw+a0np2QJM1uo059/kKSFwELq+rzSXYEtuvbNUnSbDHqVwwc\nD1wCfLCV5gGf7tUpSdLsMuoEgZOAVwHr4T+/SO0HpmuQZFmSe5LcOFQ7LcnqJNe31+uGtp2cZFWS\nm5McNlQ/KMkNbduZSdLqz01yUatfnWTBUJtjk9zSXseOeI6SpE5GDZtHqurRiZUk2zP4O5vpnAsc\nPkX9jKp6eXt9rh1vf2AJcEBr84EkE8N0ZwHHAwvba+KYxwH3VdV+DL7A7fR2rN2BU4FXAouBU5Ps\nNuJ5SpI6GDVsvpDkFGCHJK8FPg787XQNquqLwLoRj38EcGFVPVJVtwKrgMVJ9gJ2qaqr2t/4nA8c\nOdTmvLZ8CXBIu+o5DFheVeuq6j5gOVOHniRphowaNu8A1gI3AL8JfA54qt/Q+dYkX23DbBNXHPOA\nO4b2ubPV5rXlyfWN2lTVBuB+YI9pjiVJGpORwqaqnqiqD1XV0VV1VFt+Kk8TOAt4MfByYA3w50/h\nGM+YJCckWZFkxdq1a8fZFUma1UadjXZrkm9Mfj3ZD6uqu6vq8ap6AvgQg3sqAKuB+UO77t1qq9vy\n5PpGbdo9pF2Be6c51lT9ObuqFlXVojlz5jzZ05EkjWjUYbRFDJ76/BPATwNnAh9+sh/W7sFM+EUG\nj8EBuBRY0maY7ctgIsA1VbUGWJ/k4HY/5hjgM0NtJmaaHQVc2a62LgcOTbJbG6Y7tNUkSWMy6h91\n3jup9BdJrgPetak2ST4GvBrYM8mdDGaIvTrJyxnMZLuNwf0fqmplkouBm4ANwElVNfF06RMZzGzb\nAbisvQDOAS5IsorBRIQl7VjrkrwHuLbt9+6qGnWigiSpg1G/YuAVQ6vPYnClM23bqnrzFOVzptl/\nKbB0ivoK4MAp6g8DR2/iWMuAZdP1T5I0c0Z9NtrwjfwNDK5K3vSM90aSNCuNOoz2mt4dkSTNXqMO\no/3BdNur6v3PTHckSbPRk/mmzp9gMAMM4A3ANcAtPTolSZpdRg2bvYFXVNUDMHigJvDZqvqVXh2T\nJM0eo/6dzVzg0aH1R1tNkqTNGvXK5nzgmiSfautH8r2HYEqSNK1RZ6MtTXIZg6cHAPx6Vf1rv25J\nkmaTUYfRAHYE1lfVXwJ3tsfKSJK0WaM+iPNU4O3Aya30bJ7Cs9EkSdumUa9sfhF4I/AdgKq6C9i5\nV6ckSbPLqGHzaHuicgEkeX6/LkmSZptRw+biJB8EXpDkeODzDL6PRpKkzRp1Ntr7krwWWA/8EPCu\nqlretWeSpFljs2GTZDvg8+1hnAaMJOlJ2+wwWvsSsyeS7DoD/ZEkzUKjPkHgQeCGJMtpM9IAqup3\nu/RKkjSrjBo2n2wvSZKetGnDJsk+VfUfVeVz0CRJT9nm7tl8emIhySc690WSNEttLmwytPzinh2R\nJM1emwub2sSyJEkj29wEgZclWc/gCmeHtkxbr6rapWvvJEmzwrRhU1XbzVRHJEmz15P5PhtJkp4S\nw0aS1J1hI0nqzrCRJHXXLWySLEtyT5Ibh2q7J1me5Jb2vtvQtpOTrEpyc5LDhuoHJbmhbTszSVr9\nuUkuavWrkywYanNs+4xbkhzb6xwlSaPpeWVzLnD4pNo7gCuqaiFwRVsnyf7AEuCA1uYD7asNAM4C\njgcWttfEMY8D7quq/YAzgNPbsXYHTgVeCSwGTh0ONUnSzOsWNlX1RWDdpPIRwMRz1s4DjhyqX1hV\nj1TVrcAqYHGSvYBdquqq9rXU509qM3GsS4BD2lXPYcDyqlpXVfcx+A6eyaEnSZpBM33PZm5VrWnL\n3wTmtuV5wB1D+93ZavPa8uT6Rm2qagNwP7DHNMeSJI3J2CYItCuVsT4CJ8kJSVYkWbF27dpxdkWS\nZrWZDpu729AY7f2eVl8NzB/ab+9WW92WJ9c3apNke2BX4N5pjvV9qursqlpUVYvmzJnzNE5LkjSd\nmQ6bS4GJ2WHHAp8Zqi9pM8z2ZTAR4Jo25LY+ycHtfswxk9pMHOso4Mp2tXQ5cGiS3drEgENbTZI0\nJqN+U+eTluRjwKuBPZPcyWCG2HuBi5McB9wOvAmgqlYmuRi4CdgAnFRVj7dDnchgZtsOwGXtBXAO\ncEGSVQwmIixpx1qX5D3AtW2/d1fV5IkKkqQZ1C1squrNm9h0yCb2XwosnaK+AjhwivrDwNGbONYy\nYNnInZUkdeUTBCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTu\nDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ\n6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUndjCZsktyW5Icn1SVa02u5Jlie5pb3vNrT/yUlWJbk5\nyWFD9YPacVYlOTNJWv25SS5q9auTLJjpc5Qkfc84r2xeU1Uvr6pFbf0dwBVVtRC4oq2TZH9gCXAA\ncDjwgSTbtTZnAccDC9vr8FY/DrivqvYDzgBOn4HzkSRtwpY0jHYEcF5bPg84cqh+YVU9UlW3AquA\nxUn2AnapqquqqoDzJ7WZONYlwCETVz2SpJk3rrAp4PNJrktyQqvNrao1bfmbwNy2PA+4Y6jtna02\nry1Prm/Upqo2APcDezzTJyFJGs32Y/rc/1JVq5P8ALA8ydeHN1ZVJanenWhBdwLAPvvs0/vjJGmb\nNZYrm6pa3d7vAT4FLAbubkNjtPd72u6rgflDzfdutdVteXJ9ozZJtgd2Be6doh9nV9Wiqlo0Z86c\nZ+bkJEnfZ8bDJsnzk+w8sQwcCtwIXAoc23Y7FvhMW74UWNJmmO3LYCLANW3IbX2Sg9v9mGMmtZk4\n1lHAle2+jiRpDMYxjDYX+FS7X7898NGq+vsk1wIXJzkOuB14E0BVrUxyMXATsAE4qaoeb8c6ETgX\n2AG4rL0AzgEuSLIKWMdgNpskaUxmPGyq6hvAy6ao3wscsok2S4GlU9RXAAdOUX8YOPppd1aS9IzY\nkqY+S5JmKcNGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6w\nkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTu\nDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1N6vDJsnhSW5OsirJO8bdH0naVs3asEmyHfC/gZ8H9gfe\nnGT/8fZKkrZNszZsgMXAqqr6RlU9ClwIHDHmPknSNmn7cXego3nAHUPrdwKvHN4hyQnACW31wSQ3\nz1DftgV7At8adyc2J6ePuwcak63i/8+txItG2Wk2h81mVdXZwNnj7sdslGRFVS0adz+kqfj/58yb\nzcNoq4H5Q+t7t5okaYbN5rC5FliYZN8kzwGWAJeOuU+StE2atcNoVbUhye8AlwPbAcuqauWYu7Ut\ncXhSWzL//5xhqapx90GSNMvN5mE0SdIWwrCRJHVn2EiSupu1EwQ0s5L8MIMnNMxrpdXApVX1tfH1\nStKWwisbPW1J3s7gcUABrmmvAB/zAajakiX59XH3YVvhbDQ9bUn+H3BAVT02qf4cYGVVLRxPz6Tp\nJfmPqtpn3P3YFjiMpmfCE8ALgdsn1fdq26SxSfLVTW0C5s5kX7Zlho2eCW8DrkhyC997+Ok+wH7A\n74ytV9LAXOAw4L5J9QD/MvPd2TYZNnraqurvk7yUwdc6DE8QuLaqHh9fzyQA/g7Yqaqun7whyT/N\nfHe2Td6zkSR152w0SVJ3ho0kqTvDRtpCJDktyR+Nux9SD4aNJKk7w0YakyTHJPlqkn9LcsGkbccn\nubZt+0SSHVv96CQ3tvoXW+2AJNckub4dzz+i1RbH2WjSGCQ5APgU8FNV9a0kuwO/CzxYVe9LskdV\n3dv2/Z/A3VX1V0luAA6vqtVJXlBV307yV8BVVfWR9tSG7arqoXGdmzQVr2yk8fhZ4ONV9S2Aqlo3\nafuBSf5vC5e3AAe0+j8D5yY5nsE30AJ8GTilPaPuRQaNtkSGjbRlOhf4nar6UeBPgOcBVNVvAe8E\n5gPXtSugjwJvBB4CPpfkZ8fTZWnTDBtpPK4Ejk6yB0AbRhu2M7AmybMZXNnQ9ntJVV1dVe8C1gLz\nk7wY+EZVnQl8BvixGTkD6UnwcTXSGFTVyiRLgS8keRz4V+C2oV3+GLiaQaBczSB8AP5XmwAQ4Arg\n34C3A7+a5DHgm8CfzshJSE+CEwQkSd05jCZJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSp\nO8NGktTd/we8EPBSt76vtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158aaa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_class = pd.value_counts(data['Class'], sort=True).sort_index()\n",
    "count_class.plot(kind='bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions: 0.5\n",
      "Percentage of fraud transactions 0.5\n",
      "Total number of  transactions in data 984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengyi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "number_record_fraud = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "\n",
    "normal_indices = np.array(data[data.Class == 0].index)\n",
    "\n",
    "# 通过索引随机选择x\n",
    "random_normal_indices = np.random.choice(normal_indices, number_record_fraud, replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# 合并两种索引\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "\n",
    "under_sample_data = data.iloc[under_sample_indices, :]\n",
    "\n",
    "X_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.iloc[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "print(\"Percentage of normal transactions:\", len(under_sample_data[under_sample_data.Class == 0]) / len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions\", len(under_sample_data[under_sample_data.Class == 1]) / len(under_sample_data))\n",
    "print(\"Total number of  transactions in data\", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of X_train= 199364\n",
      "Number of X_test= 85443\n",
      "Number of total= 284807\n",
      "\n",
      "\n",
      "Number of X_train_undersample= 688\n",
      "Number of X_test_undersample= 296\n",
      "Number of total_undersample= 984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengyi/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# 切分原始数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number of X_train=\", len(X_train))\n",
    "print(\"Number of X_test=\", len(X_test))\n",
    "print(\"Number of total=\", len(X_train) + len(X_test))\n",
    "\n",
    "# 对下采样数据进行切分\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample, y_undersample, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Number of X_train_undersample=\", len(X_train_undersample))\n",
    "print(\"Number of X_test_undersample=\", len(X_test_undersample))\n",
    "print(\"Number of total_undersample=\", len(X_train_undersample) + len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall = TP/(TP+FN)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data, y_train_data):\n",
    "    fold = KFold(len(y_train_data), 5, shuffle=False)\n",
    "    \n",
    "    # different c parameters\n",
    "    c_param_range = [0.01, 0.1, 1, 10, 100]\n",
    "    \n",
    "    results_table = pd.DataFrame(index=range(len(c_param_range), 2), columns=['C_parameters', 'Mean recall score'])\n",
    "    results_table['C_parameters'] = c_param_range\n",
    "    \n",
    "    # the k-fold will give 2 list: train_indices = indices[0], test_indices = indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-----------------------')\n",
    "        print('C parameters', c_param)\n",
    "        print('-----------------------','\\n')\n",
    "        \n",
    "        recall_accs = []\n",
    "        # enumerate枚举, start表示下标开始的位置\n",
    "        for iteration, indices in enumerate(fold, start=1):\n",
    "            # 惩罚系数为c_param,L1正则\n",
    "            lr = LogisticRegression(C = c_param, penalty='l1')\n",
    "            lr.fit(x_train_data.iloc[indices[0],:], y_train_data.iloc[indices[0],:].values.ravel())\n",
    "            y_pred_unsersample = lr.predict(x_train_data.iloc[indices[1],:])\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values, y_pred_unsersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration', iteration, \": recall score = \", recall_acc)\n",
    "            \n",
    "        results_table.ix[j, \"Mean recall score\"] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print(\" \")\n",
    "        print(\"Mean recall score:\", np.mean(recall_accs), \"\\n\")\n",
    "        \n",
    "    base_c = results_table.loc[results_table[\"Mean recall score\"].idxmax()]['C_parameters']\n",
    "    \n",
    "    print(\"*************************\")\n",
    "    print(\"Best c_param = \", base_c)\n",
    "    print(\"*************************\")\n",
    "    \n",
    "    return base_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "C parameters 0.01\n",
      "----------------------- \n",
      "\n",
      "Iteration 1 : recall score =  0.958904109589041\n",
      "Iteration 2 : recall score =  0.9315068493150684\n",
      "Iteration 3 : recall score =  1.0\n",
      "Iteration 4 : recall score =  0.972972972972973\n",
      "Iteration 5 : recall score =  0.9848484848484849\n",
      " \n",
      "Mean recall score: 0.9696464833451135 \n",
      "\n",
      "-----------------------\n",
      "C parameters 0.1\n",
      "----------------------- \n",
      "\n",
      "Iteration 1 : recall score =  0.8493150684931506\n",
      "Iteration 2 : recall score =  0.863013698630137\n",
      "Iteration 3 : recall score =  0.9322033898305084\n",
      "Iteration 4 : recall score =  0.9324324324324325\n",
      "Iteration 5 : recall score =  0.8787878787878788\n",
      " \n",
      "Mean recall score: 0.8911504936348214 \n",
      "\n",
      "-----------------------\n",
      "C parameters 1\n",
      "----------------------- \n",
      "\n",
      "Iteration 1 : recall score =  0.863013698630137\n",
      "Iteration 2 : recall score =  0.8767123287671232\n",
      "Iteration 3 : recall score =  0.9661016949152542\n",
      "Iteration 4 : recall score =  0.9459459459459459\n",
      "Iteration 5 : recall score =  0.8939393939393939\n",
      " \n",
      "Mean recall score: 0.9091426124395708 \n",
      "\n",
      "-----------------------\n",
      "C parameters 10\n",
      "----------------------- \n",
      "\n",
      "Iteration 1 : recall score =  0.863013698630137\n",
      "Iteration 2 : recall score =  0.8904109589041096\n",
      "Iteration 3 : recall score =  0.9661016949152542\n",
      "Iteration 4 : recall score =  0.9459459459459459\n",
      "Iteration 5 : recall score =  0.9090909090909091\n",
      " \n",
      "Mean recall score: 0.9149126414972711 \n",
      "\n",
      "-----------------------\n",
      "C parameters 100\n",
      "----------------------- \n",
      "\n",
      "Iteration 1 : recall score =  0.863013698630137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pengyi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 : recall score =  0.8904109589041096\n",
      "Iteration 3 : recall score =  0.9830508474576272\n",
      "Iteration 4 : recall score =  0.9459459459459459\n",
      "Iteration 5 : recall score =  0.9090909090909091\n",
      " \n",
      "Mean recall score: 0.9183024720057457 \n",
      "\n",
      "*************************\n",
      "Best c_param =  0.01\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "base_c = printing_Kfold_scores(X_train_undersample, y_train_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
